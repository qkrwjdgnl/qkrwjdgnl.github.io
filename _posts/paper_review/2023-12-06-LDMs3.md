---
title: "High-Resolution Image Synthesis with Latent Diffusion Models (II)"
classes: wide
---

<figure align="center">
  <img src="{{ '/assets/image/LDM3/0.png' | relative_url }}" width="50%">
</figure>

# 기초부터 이해하는 Stable Diffusion (II): 어떻게 훈련하는가

몇 달 전, AIGC가 대유행을 일으키면서 고화질의 생성 이미지가 계속해서 등장했고, 그 중에서도 가장 중요한 오픈소스 모델인 Stable Diffusion이 기술적, 상업적으로 큰 인기를 끌었습니다. 이 모델은 빠른 속도로 지속적으로 발전하고 있습니다. 이전에 관련 지식이 없었던 초보자로서, 관련 기술 지식을 이해하기 위해 많은 글을 찾아보았고, 마침내 Jay Alammar의 글이 가장 이해하기 쉽다는 것을 발견하였습니다. 그래서 이 글을 간단히 번역하기로 결정했습니다. 이를 통해 더 많은 사람들이 이 강력한 기술을 처음부터 이해할 수 있게 돕고자 합니다.

원문이 길기 때문에, 여기서는 세 편의 글로 나누어 설명하겠습니다:

1. [첫 번째 편](https://qkrwjdgnl.github.io/LDMs/), '**무엇인가**'에 대해 주로 다룹니다. 여기에는 Stable Diffusion이 무엇인지, 그 안의 각 모듈이 무엇인지가 포함됩니다.
2. [두 번째 편](https://qkrwjdgnl.github.io/LDMs2/), '**어떻게 하는가**'에 대해 다룹니다. 즉, Diffusion이 어떻게 훈련되고 사용되는지에 대한 문제입니다.
3. 세 번째 편, 이 글에서는 '**어떻게 하는가**'에 대해 다룹니다. 구체적으로, 의미 정보가 생성 이미지 과정에 어떻게 영향을 미치는지에 대해 설명합니다.

이제 본격적으로 세 번째 글의 소개에 들어가서, Stable Diffusion이 무엇인지, 그리고 그 안의 일부 모듈이 무엇인지에 대해 이야기해 보겠습니다.

> 원문 링크: [The Illustrated Stable Diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)<br>
> 저자: Jay Alammar<br>
> 번역자: Zhenghui Piao

