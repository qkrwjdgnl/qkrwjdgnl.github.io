---
title: "DiffFit: Unlocking Transferability of Large Diffusion Models
via Simple Parameter-Efficient Fine-Tuning"
classes: wide
use_math: true
---

<figure align="center">
  <img src="{{ '/assets/image/2023-12-17-DiffFit/0.png' | relative_url }}" width="50%">
</figure>

> **원문 링크**: [[paper](https://arxiv.org/pdf/2304.06648.pdf)]<br>
> **저자**: Enze Xie, Lewei Yao, Han Shi, Zhili Liu, Daquan Zhou, Zhaoqiang Liu, Jiawei Li, Zhenguo Li<br>
> [Huawei Noah’s Ark Lab]<br>
> [[Github](https://github.com/mkshing/DiffFit-pytorch)]<br>
> [27 Jul 2023]<br>
> **번역자**: Zhenghui Piao

확산 모델은 고화질 이미지 생성에서 매우 효과적임이 입증됐다. 하지만 대규모 사전 훈련된 확산 모델을 새로운 분야에 적응시키는 것은 여전히 도전적이고, 실제 응용에서 중요하다. 이 논문에서는 DiffFit을 제안한다. 이는 대규모 사전 훈련된 확산 모델을 미세 조정해 새로운 분야에 빠르게 적응할 수 있는 효율적인 파라미터 미세 조정 전략이다. DiffFit은 매우 단순하면서도 특정 층의 바이어스 항목과 새로 추가된 스케일링 요소만을 미세 조정해 훈련 속도를 현저히 높이고 모델 저장 비용을 줄인다. 전체 모델을 미세 조정하는 것에 비해 DiffFit은 훈련 속도를 2배 가속시키며, 전체 모델 파라미터의 약 0.12%만을 저장한다. 스케일링 요소가 빠른 적응에 효과적임을 입증하는 직관적인 이론 분석도 제공된다. 8개의 하위 데이터셋(8 downstream datasets)에서 DiffFit의 성능은 전체 모델 미세 조정과 비교해 우수하거나 동등하며 효율적이다. 특히, 사전 훈련된 저해상도 생성 모델을 최소한의 비용으로 고해상도에 적응시키는 방법을 보여준다. 확산 기반 방법에서 DiffFit은 ImageNet 256×256의 공개 사전 훈련된 체크포인트를 기반으로 25개의 에포크 동안 미세 조정하여 FID에서 새로운 기록을 달성했다. 이는 3.02에 달하며, 가장 가까운 경쟁자보다 30배 더 효율적이다.





